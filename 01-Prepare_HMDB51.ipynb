{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1504a522-3ed6-4fd0-bb11-064a65ef98f9",
   "metadata": {},
   "source": [
    "We'll download the HMDB-51 dataset (2GB) and extract videos into frames of images.\n",
    "\n",
    "You need one HDD (slow) and one SSD (fast) storages. We'll make symbolic links into the `data/` directory.  \n",
    "We assume the path of each is `/storage/kiyoon` and `/faster/kiyoon` respectively, but rename it regarding your system.\n",
    "\n",
    "Note that the paths to directories are defined in `dataset_configs/hmdb.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c914c937-be9e-4b9a-995a-78bbdc2282a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PYVIDEOAI_DIR=/home/kiyoon/project/PyVideoAI\n",
      "env: DATA_DIR=/home/kiyoon/project/PyVideoAI/data\n",
      "env: HDD_PATH=/storage/kiyoon\n",
      "env: SSD_PATH=/faster/kiyoon\n"
     ]
    }
   ],
   "source": [
    "# Environments for future use\n",
    "from pyvideoai.config import PYVIDEOAI_DIR, DATA_DIR, DEFAULT_EXPERIMENT_ROOT\n",
    "%env PYVIDEOAI_DIR=$PYVIDEOAI_DIR\n",
    "%env DATA_DIR=$DATA_DIR\n",
    "%env EXPERIMENT_ROOT=$DEFAULT_EXPERIMENT_ROOT\n",
    "\n",
    "# !! CHANGE BELOW\n",
    "%env HDD_PATH=/storage/kiyoon\n",
    "%env SSD_PATH=/faster/kiyoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "78888c4e-0a11-4cda-8702-d75ac4953aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory preparation\n",
    "# Make soft links in data/ directory\n",
    "\n",
    "!mkdir -p \"$HDD_PATH/datasets/hmdb51\"\n",
    "!mkdir -p \"$SSD_PATH/datasets/hmdb51/frames_q5\"\n",
    "!mkdir \"$DATA_DIR\"\n",
    "!ln -s \"$HDD_PATH/datasets/hmdb51\" \"$DATA_DIR/\"\n",
    "!ln -s \"$SSD_PATH/datasets/hmdb51/frames_q5\" \"$DATA_DIR/hmdb51/\"\n",
    "\n",
    "# Make experiments output directory as well\n",
    "!mkdir -p \"$HDD_PATH/PyVideoAI_experiments\"\n",
    "!ln -s \"$HDD_PATH/PyVideoAI_experiments\" \"$EXPERIMENT_ROOT\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb66e7ae-9c95-4ecb-adbe-7e0ba6c959d8",
   "metadata": {},
   "source": [
    "Now that we have all directories setup, we'll download and extract the RAR archived files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "22c3107b-62aa-4226-9e62-c9296f69c4cf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading video data\n",
      "--2021-06-13 03:52:39--  http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
      "Resolving serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)... 128.148.254.114\n",
      "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar [following]\n",
      "--2021-06-13 03:52:40--  https://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/hmdb51_org.rar\n",
      "Connecting to serre-lab.clps.brown.edu (serre-lab.clps.brown.edu)|128.148.254.114|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2124008126 (2.0G)\n",
      "Saving to: ‚Äò/home/kiyoon/project/PyVideoAI/data/hmdb51/hmdb51_org.rar‚Äô\n",
      "\n",
      "/home/kiyoon/projec 100%[===================>]   1.98G   682KB/s    in 38m 46s \n",
      "\n",
      "2021-06-13 04:31:27 (892 KB/s) - ‚Äò/home/kiyoon/project/PyVideoAI/data/hmdb51/hmdb51_org.rar‚Äô saved [2124008126/2124008126]\n",
      "\n",
      "Extracting video data\n",
      "\n",
      "UNRAR 5.61 beta 1 freeware      Copyright (c) 1993-2018 Alexander Roshal\n",
      "\n",
      "\n",
      "Extracting from /home/kiyoon/project/PyVideoAI/data/hmdb51/hmdb51_org.rar\n",
      "\n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/videos/shoot_gun.rar       1  OK \n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/videos/sit.rar         3  OK \n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/videos/situp.rar       4  OK \n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/videos/smile.rar       5  OK \n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/videos/smoke.rar         7  OK \n",
      "-----------------------------------------------------------\n",
      "----------OUTPUT SIMPLIFIED FOR NOTEBOOK VIEWERS-----------\n",
      "-----------------------------------------------------------\n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/testTrainMulti_7030_splits/walk_test_split3.txt    97  OK \n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/testTrainMulti_7030_splits/wave_test_split1.txt    98  OK \n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/testTrainMulti_7030_splits/wave_test_split2.txt    99  OK \n",
      "Extracting  /home/kiyoon/project/PyVideoAI/data/hmdb51/testTrainMulti_7030_splits/wave_test_split3.txt    99  OK \n",
      "All OK\n",
      "Removing splits rar\n"
     ]
    }
   ],
   "source": [
    "# Download HMDB dataset in `data/hmdb51`\n",
    "# It will also download the splits and extract the rar files\n",
    "!bash \"$PYVIDEOAI_DIR/submodules/video_datasets_api/hmdb_tools/download_hmdb.sh\" \"$DATA_DIR/hmdb51\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828ce293-397c-4647-b6ed-7a5ab10743ef",
   "metadata": {},
   "source": [
    "You should see \\*.avi videos in `data/hmdb51/videos`,  \n",
    "and annotations saved in `data/hmdb51/testTrainMulti_7030_splits`.\n",
    "\n",
    "Next, we're extracting videos into frames of images to `data/hmdb51/frames_q5` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96df3f15-0241-4c4c-88ed-634731078bb8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 6766\n",
      "/home/kiyoon/project/PyVideoAI/data/hmdb51/frames_q5/pushup/push_ups_pushup_f_nm_np1_ri_goo_1\n",
      "Average processing time per segment: 0.08, ETA: 518\n",
      "2 / 6766\n",
      "/home/kiyoon/project/PyVideoAI/data/hmdb51/frames_q5/pushup/push-up_or_shut_up_(IXK)_pushup_f_cm_np1_le_med_2\n",
      "Average processing time per segment: 0.06, ETA: 413\n",
      "3 / 6766\n",
      "/home/kiyoon/project/PyVideoAI/data/hmdb51/frames_q5/pushup/100_Push-ups_Initial_Test_hundredpushups_com_pushup_f_nm_np1_fr_goo_1\n",
      "Average processing time per segment: 0.05, ETA: 370\n",
      "4 / 6766\n",
      "/home/kiyoon/project/PyVideoAI/data/hmdb51/frames_q5/pushup/YOUTUBE_PUSH_UP_CHALLENGE_pushup_f_cm_np1_fr_med_1\n",
      "Average processing time per segment: 0.05, ETA: 351\n",
      "-----------------------------------------------------------\n",
      "----------OUTPUT SIMPLIFIED FOR NOTEBOOK VIEWERS-----------\n",
      "-----------------------------------------------------------\n",
      "6765 / 6766\n",
      "/home/kiyoon/project/PyVideoAI/data/hmdb51/frames_q5/walk/Veoh_Alpha_Dog_2_walk_f_nm_np4_fr_med_16\n",
      "Average processing time per segment: 0.05, ETA: 0\n",
      "6766 / 6766\n",
      "/home/kiyoon/project/PyVideoAI/data/hmdb51/frames_q5/walk/Panic_in_the_Streets_walk_f_cm_np1_fr_med_11\n",
      "Average processing time per segment: 0.05, ETA: 0\n",
      "üòç All videos successfully extracted\n"
     ]
    }
   ],
   "source": [
    "# Extract videos into frames of images (quality=5)\n",
    "# This will be saved in the fast SSD storage.\n",
    "# You can SKIP this if you want to use video decoding dataloader.\n",
    "!bash \"$PYVIDEOAI_DIR/submodules/video_datasets_api/hmdb_tools/hmdb_extract_frames.sh\" \"$DATA_DIR/hmdb51/videos\" \"$DATA_DIR/hmdb51/frames_q5\" 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031b4e7-c16e-4fe1-b9d4-357998d9f2a2",
   "metadata": {},
   "source": [
    "We'll convert the official split labels into the format that our dataloader expects, and we provide code for this.  \n",
    "If you want to know the details of the format, below explains what it is like:\n",
    "\n",
    "**Format used in** `FramesSparsesampleDataloader` in `dataloader/frames_sparsesample_dataloader.py`    \n",
    "**or** `FramesDensesampleDataloader` in `dataloader/frames_densesample_dataloader.py`  \n",
    "\n",
    "```\n",
    "num_classes if multilabel else 0\n",
    "path/to/frames/dir_1/{:05d}.jpg video_id_1 label_1 start_frame_idx_1 end_frame_idx_1\n",
    "path/to/frames/dir_2/{:05d}.jpg video_id_2 label_2 start_frame_idx_2 end_frame_idx_2\n",
    "...\n",
    "path/to/frames/dir_N/{:05d}.jpg video_id_N label_N start_frame_idx_N end_frame_idx_N\n",
    "```\n",
    "\n",
    "### 1. First line: one-hot encoding or not\n",
    "\n",
    "#### TL;DR\n",
    "The first line has to be 0 for single-label classification, and `num_classes` for multi-label classification task.\n",
    "In HMDB-51, it has to be 0.\n",
    "\n",
    "#### Details\n",
    "If the value is greater than 0, the dataloader will one-hot encode the labels and return as array of size `num_classes` (which is necessary for multi-label).  \n",
    "If the value is 0, the dataloader will return the labels as integers (which is for single-label).\n",
    "\n",
    "### 2. Second line ~ end\n",
    "#### Image path\n",
    "This has to be Python-style formattable string, where the {:05d} part will be replaced by the frame index with 5-length zero paddings.  \n",
    "Also, this path can be relative and you can provide `path_prefix` argument to the dataloader.\n",
    "\n",
    "#### Video ID\n",
    "Here, the video_id has to be unique per video, and will be used for multiple-clip evaluation (multicrop evaluation).\n",
    "To elaborate, the accuracy calculator will average the prediction of the videos with the same video ID,  \n",
    "and the dataloader will automatically sample each video into multiple clips in different spatial-temporal location,  \n",
    "so all you need to do is to make sure that the video ID is unique.\n",
    "\n",
    "#### Label\n",
    "One label integer for single-label, and comma-separated labels for multi-label task.\n",
    "\n",
    "#### Start/end frame index\n",
    "Video will be sampled from `start_frame_idx` to `end_frame_idx` (including edge indices).  \n",
    "Since the extraction code above count frames from zero, the `start_frame_idx` has to be always zero in this HMDB-51 example.  \n",
    "Note that when you have long untrimmed video, you can define subclips changing this starting and ending frame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "04283255-b76f-414c-8f6b-881d68db9e17",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brush_hair\n",
      "cartwheel\n",
      "catch\n",
      "chew\n",
      "clap\n",
      "climb\n",
      "climb_stairs\n",
      "dive\n",
      "draw_sword\n",
      "dribble\n",
      "drink\n",
      "eat\n",
      "fall_floor\n",
      "fencing\n",
      "flic_flac\n",
      "golf\n",
      "handstand\n",
      "hit\n",
      "hug\n",
      "jump\n",
      "kick\n",
      "kick_ball\n",
      "kiss\n",
      "laugh\n",
      "pick\n",
      "pour\n",
      "pullup\n",
      "punch\n",
      "push\n",
      "pushup\n",
      "ride_bike\n",
      "ride_horse\n",
      "run\n",
      "shake_hands\n",
      "shoot_ball\n",
      "shoot_bow\n",
      "shoot_gun\n",
      "sit\n",
      "situp\n",
      "smile\n",
      "smoke\n",
      "somersault\n",
      "stand\n",
      "swing_baseball\n",
      "sword\n",
      "sword_exercise\n",
      "talk\n",
      "throw\n",
      "turn\n",
      "walk\n",
      "wave\n"
     ]
    }
   ],
   "source": [
    "# Generate splits in the FramesSparsesampleDataloader format (using the official splits)\n",
    "# in `data/hmdb51/splits_frames` directory\n",
    "!bash \"$PYVIDEOAI_DIR/tools/datasets/hmdb_splits_to_csv_frame_extracted.sh\" \"$DATA_DIR/hmdb51/\"{testTrainMulti_7030_splits,frames_q5,splits_frames}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66221963-c15d-4cda-945b-1176a7d1cc1f",
   "metadata": {},
   "source": [
    "Let's take a look at how the actual CSV files look like.  \n",
    "Note that the first line is 0, and the Video IDs are unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b5c8285a-9562-4d44-b3ca-b141f397191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "brush_hair/April_09_brush_hair_u_nm_np1_ba_goo_0/{:05d}.jpg 0 0 0 407\n",
      "brush_hair/April_09_brush_hair_u_nm_np1_ba_goo_1/{:05d}.jpg 1 0 0 393\n",
      "brush_hair/April_09_brush_hair_u_nm_np1_ba_goo_2/{:05d}.jpg 2 0 0 321\n",
      "brush_hair/Aussie_Brunette_Brushing_Hair_II_brush_hair_u_nm_np1_ri_med_3/{:05d}.jpg 3 0 0 157\n",
      "brush_hair/Aussie_Brunette_Brushing_Hair_II_brush_hair_u_nm_np2_le_goo_0/{:05d}.jpg 4 0 0 135\n",
      "brush_hair/Aussie_Brunette_Brushing_Hair_II_brush_hair_u_nm_np2_le_goo_1/{:05d}.jpg 5 0 0 357\n",
      "brush_hair/Aussie_Brunette_Brushing_Hair_II_brush_hair_u_nm_np2_le_med_2/{:05d}.jpg 6 0 0 189\n",
      "brush_hair/Blonde_being_brushed_brush_hair_f_nm_np2_ri_med_0/{:05d}.jpg 7 0 0 77\n",
      "brush_hair/Blonde_being_brushed_brush_hair_u_cm_np2_ri_med_1/{:05d}.jpg 8 0 0 272\n"
     ]
    }
   ],
   "source": [
    "# Print 10 lines\n",
    "!head \"$DATA_DIR/hmdb51/splits_frames/train1.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ace24d7-bb75-42ac-91c6-02ef0f05c9ee",
   "metadata": {},
   "source": [
    "Now the data preparation is complete!  \n",
    "In the next tutorial, you'll learn how to run an example code with an example configuration!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
